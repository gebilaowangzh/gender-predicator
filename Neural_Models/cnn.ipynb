{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-27T19:30:38.382662Z",
     "iopub.status.busy": "2022-03-27T19:30:38.381765Z",
     "iopub.status.idle": "2022-03-27T19:30:38.389793Z",
     "shell.execute_reply": "2022-03-27T19:30:38.389173Z",
     "shell.execute_reply.started": "2022-03-27T19:30:38.382613Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relabel(g, reverse=False):\n",
    "    if reverse:\n",
    "        return {0: 'M', 1: 'F', 2: 'U'}[g]\n",
    "    return {'M': 0, 'F': 1, 'U': 2}[g]\n",
    "\n",
    "\n",
    "def data_loader(filepath, num_row_skip=1, exclude_u=False):\n",
    "    def readFile(path):\n",
    "        f = open(path, 'r')\n",
    "        for _ in range(num_row_skip):\n",
    "            next(f)\n",
    "        out = []\n",
    "        for line in f:\n",
    "            line = line.split('\\t')\n",
    "            name, gender = line[-2], relabel(line[-1].strip())\n",
    "            if exclude_u:\n",
    "                if gender != 'U':\n",
    "                    out.append([name, gender])\n",
    "            else:\n",
    "                out.append([name, gender])\n",
    "        return out\n",
    "    \n",
    "    if isinstance(filepath, str):\n",
    "        return readFile(filepath)\n",
    "    elif isinstance(filepath, list):\n",
    "        return [readFile(path) for path in filepath]\n",
    "    else:\n",
    "         raise TypeError('filepath must be either a str or a list.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-27T19:30:38.391193Z",
     "iopub.status.busy": "2022-03-27T19:30:38.390961Z",
     "iopub.status.idle": "2022-03-27T19:30:48.341027Z",
     "shell.execute_reply": "2022-03-27T19:30:48.340081Z",
     "shell.execute_reply.started": "2022-03-27T19:30:38.391171Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3658109, [['陈品如', 0], ['陈祥旭', 0], ['陈晓', 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccnc = data_loader('data/data96861/ccnc.txt')\n",
    "len(ccnc), ccnc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-27T19:30:48.342893Z",
     "iopub.status.busy": "2022-03-27T19:30:48.342581Z",
     "iopub.status.idle": "2022-03-27T19:30:48.348045Z",
     "shell.execute_reply": "2022-03-27T19:30:48.347216Z",
     "shell.execute_reply.started": "2022-03-27T19:30:48.342865Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import seed, shuffle \n",
    "\n",
    "\n",
    "def train_dev_test_split(data, train=0.6, dev=0.2, test=0.2, seed_idx=5):\n",
    "    seed(seed_idx)\n",
    "    shuffle(data)\n",
    "    length = len(data)\n",
    "    boundary1 = round(length * train)\n",
    "    boundary2 = round(length * (train + dev))    \n",
    "    return data[:boundary1], data[boundary1: boundary2], data[boundary2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T19:30:48.349322Z",
     "iopub.status.busy": "2022-03-27T19:30:48.349135Z",
     "iopub.status.idle": "2022-03-27T19:30:53.246118Z",
     "shell.execute_reply": "2022-03-27T19:30:53.245518Z",
     "shell.execute_reply.started": "2022-03-27T19:30:48.349297Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2194865, 731622, 731622)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, dev_set, test_set = train_dev_test_split(ccnc)\n",
    "len(train_set), len(dev_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T19:30:53.248184Z",
     "iopub.status.busy": "2022-03-27T19:30:53.247804Z",
     "iopub.status.idle": "2022-03-27T19:30:56.081895Z",
     "shell.execute_reply": "2022-03-27T19:30:56.081117Z",
     "shell.execute_reply.started": "2022-03-27T19:30:53.248156Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import MapDataset\n",
    "from paddle.io import BatchSampler, DataLoader\n",
    "from paddlenlp.data import Pad, Stack, Tuple\n",
    "from paddlenlp.data import Vocab\n",
    "\n",
    "\n",
    "class TextVectorizer:\n",
    "     \n",
    "    def __init__(self, tokenizer=None):\n",
    "        self.tokenize = tokenizer\n",
    "        self.vocab_to_idx = None\n",
    "        self._V = None\n",
    "    \n",
    "    def build_vocab(self, text):\n",
    "        tokens = list(map(self.tokenize, text))\n",
    "        self._V = Vocab.build_vocab(tokens, unk_token='[UNK]', pad_token='[PAD]')\n",
    "        self.vocab_to_idx = self._V.token_to_idx\n",
    "        \n",
    "    def text_encoder(self, text):\n",
    "        if isinstance(text, list):\n",
    "            return [self(t) for t in text]\n",
    "        \n",
    "        tks = self.tokenize(text)\n",
    "        out = [self.vocab_to_idx[tk] for tk in tks]\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vocab_to_idx)\n",
    "\n",
    "    def __getitem__(self, w):\n",
    "        return self.vocab_to_idx[w]\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        if self.vocab_to_idx:\n",
    "            return self.text_encoder(text)\n",
    "        raise ValueError(\"No vocab is built!\")\n",
    "\n",
    "\n",
    "def example_converter(example, text_encoder, include_seq_len):\n",
    "    \n",
    "    text, label = example\n",
    "    encoded = text_encoder(text)\n",
    "    if include_seq_len:\n",
    "        text_len = len(encoded)\n",
    "        return encoded, text_len, label\n",
    "    return encoded, label\n",
    "\n",
    "\n",
    "def get_trans_fn(text_encoder, include_seq_len):\n",
    "    return lambda ex: example_converter(ex, text_encoder, include_seq_len)\n",
    "\n",
    "\n",
    "def get_batchify_fn(include_seq_len):\n",
    "    \n",
    "    if include_seq_len:\n",
    "        stack = [Stack(dtype=\"int64\")] * 2\n",
    "    else:\n",
    "        stack = [Stack(dtype=\"int64\")]\n",
    "    \n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=0),  \n",
    "        *stack\n",
    "    ): fn(samples)\n",
    "    \n",
    "    return batchify_fn\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, \n",
    "                      trans_fn, \n",
    "                      batchify_fn, \n",
    "                      batch_size=128, \n",
    "                      shuffle=True, \n",
    "                      sampler=BatchSampler):\n",
    "\n",
    "    if not isinstance(dataset, MapDataset):\n",
    "        dataset = MapDataset(dataset)\n",
    "        \n",
    "    dataset.map(trans_fn)\n",
    "    batch_sampler = sampler(dataset, \n",
    "                            shuffle=shuffle, \n",
    "                            batch_size=batch_size)\n",
    "    \n",
    "    dataloder = DataLoader(dataset, \n",
    "                           batch_sampler=batch_sampler, \n",
    "                           collate_fn=batchify_fn)\n",
    "    \n",
    "    return dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T19:30:56.083428Z",
     "iopub.status.busy": "2022-03-27T19:30:56.083107Z",
     "iopub.status.idle": "2022-03-27T19:31:11.356135Z",
     "shell.execute_reply": "2022-03-27T19:31:11.355502Z",
     "shell.execute_reply.started": "2022-03-27T19:30:56.083396Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocab (char): 6255\n"
     ]
    }
   ],
   "source": [
    "text = [t[0] for t in train_set]\n",
    "V = TextVectorizer(list)\n",
    "V.build_vocab(text)\n",
    "print(\"Number of vocab (char):\", len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T19:31:11.357727Z",
     "iopub.status.busy": "2022-03-27T19:31:11.357217Z",
     "iopub.status.idle": "2022-03-27T19:31:11.362326Z",
     "shell.execute_reply": "2022-03-27T19:31:11.361700Z",
     "shell.execute_reply.started": "2022-03-27T19:31:11.357695Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "include_seq_len = False; batch_size = 1024\n",
    "trans_fn = get_trans_fn(V, include_seq_len=include_seq_len)\n",
    "batchify_fn = get_batchify_fn(include_seq_len=include_seq_len)\n",
    "train_loader = create_dataloader(train_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "dev_loader = create_dataloader(dev_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "test_loader = create_dataloader(test_set, trans_fn, batchify_fn, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T19:31:11.363823Z",
     "iopub.status.busy": "2022-03-27T19:31:11.363436Z",
     "iopub.status.idle": "2022-03-27T19:31:11.372368Z",
     "shell.execute_reply": "2022-03-27T19:31:11.371646Z",
     "shell.execute_reply.started": "2022-03-27T19:31:11.363799Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle \n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "\n",
    "class CNN(nn.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 output_dim,\n",
    "                 embedding_dim=30,\n",
    "                 padding_idx=0,\n",
    "                 num_filter=256,\n",
    "                 filter_sizes=(3,),\n",
    "                 hidden_dim=15,\n",
    "                 activation=nn.ReLU()):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        \n",
    "        self.convs = nn.LayerList([\n",
    "            nn.Conv1D(\n",
    "                in_channels=embedding_dim,\n",
    "                out_channels=num_filter,\n",
    "                kernel_size=fz\n",
    "            ) for fz in filter_sizes\n",
    "        ])\n",
    "        self.dense = nn.Linear(len(filter_sizes) * num_filter, hidden_dim)\n",
    "        self.activation = activation\n",
    "        self.dense_out = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def encoder(self, embd):\n",
    "        embd = embd.transpose((0,2,1))\n",
    "        conved = [self.activation(conv(embd)) for conv in self.convs]\n",
    "        max_pooled = [F.adaptive_max_pool1d(conv, output_size=1).squeeze(2) for conv in conved]\n",
    "        pooled_concat = paddle.concat(max_pooled, axis=1)\n",
    "        return pooled_concat\n",
    " \n",
    "    def forward(self, text_ids):\n",
    "        text_embd = self.embedding(text_ids)\n",
    "        encoded = self.encoder(text_embd)\n",
    "        hidden_out = self.activation(self.dense(encoded))\n",
    "        out_logits = self.dense_out(hidden_out)\n",
    "        return out_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T19:31:11.373257Z",
     "iopub.status.busy": "2022-03-27T19:31:11.373103Z",
     "iopub.status.idle": "2022-03-27T19:31:11.378634Z",
     "shell.execute_reply": "2022-03-27T19:31:11.377928Z",
     "shell.execute_reply.started": "2022-03-27T19:31:11.373238Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "epoch = 20\n",
    "weight_decay = 0.0\n",
    "warmup_proportion = 0.0\n",
    "lr_scheduler = LinearDecayWithWarmup(5e-3, len(train_loader) * epoch, warmup_proportion)\n",
    "\n",
    "def get_model(model):\n",
    "    decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "    optimizer = paddle.optimizer.AdamW(\n",
    "    parameters=model.parameters(), \n",
    "    learning_rate=lr_scheduler, \n",
    "    weight_decay=weight_decay, \n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "    criterion = paddle.nn.CrossEntropyLoss()\n",
    "\n",
    "    model = paddle.Model(model)\n",
    "    metric = paddle.metric.Accuracy()\n",
    "    model.prepare(optimizer, criterion, metric)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T19:31:11.379713Z",
     "iopub.status.busy": "2022-03-27T19:31:11.379352Z",
     "iopub.status.idle": "2022-03-27T19:31:15.974787Z",
     "shell.execute_reply": "2022-03-27T19:31:15.974050Z",
     "shell.execute_reply.started": "2022-03-27T19:31:11.379691Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0328 03:31:11.381294 12201 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0328 03:31:11.385860 12201 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "model = CNN(len(V), 3)\n",
    "model = get_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T19:31:15.977482Z",
     "iopub.status.busy": "2022-03-27T19:31:15.977043Z",
     "iopub.status.idle": "2022-03-27T19:40:16.621760Z",
     "shell.execute_reply": "2022-03-27T19:40:16.621085Z",
     "shell.execute_reply.started": "2022-03-27T19:31:15.977454Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/20\n",
      "step 1000/2144 - loss: 0.0964 - acc: 0.9493 - 16ms/step\n",
      "step 2000/2144 - loss: 0.0662 - acc: 0.9573 - 16ms/step\n",
      "step 2144/2144 - loss: 0.0611 - acc: 0.9579 - 16ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0663 - acc: 0.9682 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 2/20\n",
      "step 1000/2144 - loss: 0.0667 - acc: 0.9700 - 16ms/step\n",
      "step 2000/2144 - loss: 0.0511 - acc: 0.9705 - 16ms/step\n",
      "step 2144/2144 - loss: 0.0870 - acc: 0.9706 - 16ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0591 - acc: 0.9711 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 3/20\n",
      "step 1000/2144 - loss: 0.0658 - acc: 0.9732 - 16ms/step\n",
      "step 2000/2144 - loss: 0.0503 - acc: 0.9734 - 16ms/step\n",
      "step 2144/2144 - loss: 0.0597 - acc: 0.9735 - 16ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0405 - acc: 0.9728 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 4/20\n",
      "step 1000/2144 - loss: 0.0535 - acc: 0.9751 - 16ms/step\n",
      "step 2000/2144 - loss: 0.0611 - acc: 0.9750 - 17ms/step\n",
      "step 2144/2144 - loss: 0.0719 - acc: 0.9750 - 17ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0533 - acc: 0.9738 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 5/20\n",
      "step 1000/2144 - loss: 0.0463 - acc: 0.9764 - 16ms/step\n",
      "step 2000/2144 - loss: 0.0635 - acc: 0.9762 - 16ms/step\n",
      "step 2144/2144 - loss: 0.0533 - acc: 0.9762 - 16ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0448 - acc: 0.9743 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 6/20\n",
      "step 1000/2144 - loss: 0.0506 - acc: 0.9770 - 16ms/step\n",
      "step 2000/2144 - loss: 0.0454 - acc: 0.9769 - 16ms/step\n",
      "step 2144/2144 - loss: 0.0367 - acc: 0.9769 - 16ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0618 - acc: 0.9745 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 7/20\n",
      "step 1000/2144 - loss: 0.0552 - acc: 0.9777 - 16ms/step\n",
      "step 2000/2144 - loss: 0.0485 - acc: 0.9776 - 17ms/step\n",
      "step 2144/2144 - loss: 0.0636 - acc: 0.9775 - 17ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0339 - acc: 0.9751 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 8/20\n",
      "step 1000/2144 - loss: 0.0447 - acc: 0.9784 - 16ms/step\n",
      "step 2000/2144 - loss: 0.0472 - acc: 0.9781 - 16ms/step\n",
      "step 2144/2144 - loss: 0.0563 - acc: 0.9781 - 16ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0461 - acc: 0.9750 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 9/20\n",
      "step 1000/2144 - loss: 0.0491 - acc: 0.9787 - 16ms/step\n",
      "step 2000/2144 - loss: 0.0432 - acc: 0.9786 - 16ms/step\n",
      "step 2144/2144 - loss: 0.0240 - acc: 0.9785 - 16ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0531 - acc: 0.9753 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 10/20\n",
      "step 1000/2144 - loss: 0.0464 - acc: 0.9793 - 19ms/step\n",
      "step 2000/2144 - loss: 0.0323 - acc: 0.9790 - 17ms/step\n",
      "step 2144/2144 - loss: 0.0468 - acc: 0.9789 - 17ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0754 - acc: 0.9755 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 11/20\n",
      "step 1000/2144 - loss: 0.0499 - acc: 0.9795 - 16ms/step\n",
      "step 2000/2144 - loss: 0.0357 - acc: 0.9794 - 16ms/step\n",
      "step 2144/2144 - loss: 0.0458 - acc: 0.9794 - 16ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0512 - acc: 0.9755 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 12/20\n",
      "step 1000/2144 - loss: 0.0373 - acc: 0.9801 - 16ms/step\n",
      "step 2000/2144 - loss: 0.0412 - acc: 0.9799 - 16ms/step\n",
      "step 2144/2144 - loss: 0.0320 - acc: 0.9798 - 16ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0387 - acc: 0.9751 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 12: Early stopping.\n"
     ]
    }
   ],
   "source": [
    "from paddle.callbacks import EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(patience=5)\n",
    "\n",
    "model.fit(train_loader, dev_loader, epochs=epoch, verbose=2, log_freq=1000, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T19:40:16.623256Z",
     "iopub.status.busy": "2022-03-27T19:40:16.622763Z",
     "iopub.status.idle": "2022-03-27T19:40:16.654910Z",
     "shell.execute_reply": "2022-03-27T19:40:16.654227Z",
     "shell.execute_reply.started": "2022-03-27T19:40:16.623225Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(\"ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T19:40:16.656299Z",
     "iopub.status.busy": "2022-03-27T19:40:16.655934Z",
     "iopub.status.idle": "2022-03-27T19:40:28.960276Z",
     "shell.execute_reply": "2022-03-27T19:40:28.959604Z",
     "shell.execute_reply.started": "2022-03-27T19:40:16.656266Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step  10/715 - loss: 0.0527 - acc: 0.9732 - 18ms/step\n",
      "step  20/715 - loss: 0.0581 - acc: 0.9744 - 16ms/step\n",
      "step  30/715 - loss: 0.0754 - acc: 0.9741 - 99ms/step\n",
      "step  40/715 - loss: 0.0559 - acc: 0.9744 - 78ms/step\n",
      "step  50/715 - loss: 0.0671 - acc: 0.9748 - 65ms/step\n",
      "step  60/715 - loss: 0.0637 - acc: 0.9745 - 57ms/step\n",
      "step  70/715 - loss: 0.0542 - acc: 0.9747 - 50ms/step\n",
      "step  80/715 - loss: 0.0755 - acc: 0.9747 - 46ms/step\n",
      "step  90/715 - loss: 0.0434 - acc: 0.9747 - 42ms/step\n",
      "step 100/715 - loss: 0.0469 - acc: 0.9748 - 39ms/step\n",
      "step 110/715 - loss: 0.0572 - acc: 0.9748 - 37ms/step\n",
      "step 120/715 - loss: 0.0514 - acc: 0.9747 - 35ms/step\n",
      "step 130/715 - loss: 0.0958 - acc: 0.9747 - 34ms/step\n",
      "step 140/715 - loss: 0.0526 - acc: 0.9749 - 32ms/step\n",
      "step 150/715 - loss: 0.0452 - acc: 0.9751 - 31ms/step\n",
      "step 160/715 - loss: 0.0359 - acc: 0.9750 - 30ms/step\n",
      "step 170/715 - loss: 0.0379 - acc: 0.9750 - 29ms/step\n",
      "step 180/715 - loss: 0.0759 - acc: 0.9749 - 28ms/step\n",
      "step 190/715 - loss: 0.0595 - acc: 0.9747 - 28ms/step\n",
      "step 200/715 - loss: 0.0823 - acc: 0.9747 - 27ms/step\n",
      "step 210/715 - loss: 0.0531 - acc: 0.9747 - 26ms/step\n",
      "step 220/715 - loss: 0.0990 - acc: 0.9747 - 26ms/step\n",
      "step 230/715 - loss: 0.0518 - acc: 0.9748 - 25ms/step\n",
      "step 240/715 - loss: 0.0473 - acc: 0.9749 - 25ms/step\n",
      "step 250/715 - loss: 0.0613 - acc: 0.9750 - 24ms/step\n",
      "step 260/715 - loss: 0.0468 - acc: 0.9750 - 24ms/step\n",
      "step 270/715 - loss: 0.0659 - acc: 0.9749 - 23ms/step\n",
      "step 280/715 - loss: 0.0860 - acc: 0.9750 - 23ms/step\n",
      "step 290/715 - loss: 0.0505 - acc: 0.9749 - 23ms/step\n",
      "step 300/715 - loss: 0.1359 - acc: 0.9749 - 22ms/step\n",
      "step 310/715 - loss: 0.0619 - acc: 0.9748 - 22ms/step\n",
      "step 320/715 - loss: 0.0607 - acc: 0.9749 - 22ms/step\n",
      "step 330/715 - loss: 0.0375 - acc: 0.9749 - 22ms/step\n",
      "step 340/715 - loss: 0.0795 - acc: 0.9748 - 21ms/step\n",
      "step 350/715 - loss: 0.1072 - acc: 0.9748 - 21ms/step\n",
      "step 360/715 - loss: 0.0558 - acc: 0.9748 - 21ms/step\n",
      "step 370/715 - loss: 0.0610 - acc: 0.9748 - 21ms/step\n",
      "step 380/715 - loss: 0.0535 - acc: 0.9749 - 21ms/step\n",
      "step 390/715 - loss: 0.0528 - acc: 0.9748 - 20ms/step\n",
      "step 400/715 - loss: 0.0525 - acc: 0.9749 - 20ms/step\n",
      "step 410/715 - loss: 0.0697 - acc: 0.9749 - 20ms/step\n",
      "step 420/715 - loss: 0.0596 - acc: 0.9749 - 20ms/step\n",
      "step 430/715 - loss: 0.0502 - acc: 0.9749 - 20ms/step\n",
      "step 440/715 - loss: 0.0593 - acc: 0.9749 - 20ms/step\n",
      "step 450/715 - loss: 0.0752 - acc: 0.9749 - 19ms/step\n",
      "step 460/715 - loss: 0.0547 - acc: 0.9749 - 19ms/step\n",
      "step 470/715 - loss: 0.0526 - acc: 0.9750 - 19ms/step\n",
      "step 480/715 - loss: 0.0587 - acc: 0.9750 - 19ms/step\n",
      "step 490/715 - loss: 0.0691 - acc: 0.9750 - 19ms/step\n",
      "step 500/715 - loss: 0.0459 - acc: 0.9749 - 19ms/step\n",
      "step 510/715 - loss: 0.0372 - acc: 0.9749 - 19ms/step\n",
      "step 520/715 - loss: 0.0585 - acc: 0.9749 - 19ms/step\n",
      "step 530/715 - loss: 0.0496 - acc: 0.9749 - 19ms/step\n",
      "step 540/715 - loss: 0.0552 - acc: 0.9749 - 18ms/step\n",
      "step 550/715 - loss: 0.0508 - acc: 0.9749 - 18ms/step\n",
      "step 560/715 - loss: 0.0580 - acc: 0.9749 - 18ms/step\n",
      "step 570/715 - loss: 0.0511 - acc: 0.9749 - 18ms/step\n",
      "step 580/715 - loss: 0.0745 - acc: 0.9749 - 18ms/step\n",
      "step 590/715 - loss: 0.0662 - acc: 0.9749 - 18ms/step\n",
      "step 600/715 - loss: 0.0414 - acc: 0.9749 - 18ms/step\n",
      "step 610/715 - loss: 0.0480 - acc: 0.9750 - 18ms/step\n",
      "step 620/715 - loss: 0.0575 - acc: 0.9750 - 18ms/step\n",
      "step 630/715 - loss: 0.0528 - acc: 0.9750 - 18ms/step\n",
      "step 640/715 - loss: 0.0559 - acc: 0.9750 - 18ms/step\n",
      "step 650/715 - loss: 0.0861 - acc: 0.9750 - 18ms/step\n",
      "step 660/715 - loss: 0.1039 - acc: 0.9750 - 18ms/step\n",
      "step 670/715 - loss: 0.0495 - acc: 0.9750 - 18ms/step\n",
      "step 680/715 - loss: 0.0685 - acc: 0.9750 - 17ms/step\n",
      "step 690/715 - loss: 0.0778 - acc: 0.9750 - 17ms/step\n",
      "step 700/715 - loss: 0.0460 - acc: 0.9750 - 17ms/step\n",
      "step 710/715 - loss: 0.0603 - acc: 0.9750 - 17ms/step\n",
      "step 715/715 - loss: 0.0456 - acc: 0.9749 - 17ms/step\n",
      "Eval samples: 731622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.045631748], 'acc': 0.9749488123648551}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
