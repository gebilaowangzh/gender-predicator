{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-27T17:54:45.803003Z",
     "iopub.status.busy": "2022-03-27T17:54:45.802535Z",
     "iopub.status.idle": "2022-03-27T17:54:45.809051Z",
     "shell.execute_reply": "2022-03-27T17:54:45.808447Z",
     "shell.execute_reply.started": "2022-03-27T17:54:45.802979Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relabel(g, reverse=False):\n",
    "    if reverse:\n",
    "        return {0: 'M', 1: 'F', 2: 'U'}[g]\n",
    "    return {'M': 0, 'F': 1, 'U': 2}[g]\n",
    "\n",
    "\n",
    "def data_loader(filepath, num_row_skip=1):\n",
    "    def readFile(path):\n",
    "        f = open(path, 'r')\n",
    "        for _ in range(num_row_skip):\n",
    "            next(f)\n",
    "        out = []\n",
    "        for line in f:\n",
    "            line = line.split('\\t')\n",
    "            out.append([line[-2], relabel(line[-1].strip())])\n",
    "        return out\n",
    "    \n",
    "    if isinstance(filepath, str):\n",
    "        return readFile(filepath)\n",
    "    elif isinstance(filepath, list):\n",
    "        return [readFile(path) for path in filepath]\n",
    "    else:\n",
    "         raise TypeError('filepath must be either a str or a list.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-27T17:54:45.810708Z",
     "iopub.status.busy": "2022-03-27T17:54:45.810089Z",
     "iopub.status.idle": "2022-03-27T17:54:55.417942Z",
     "shell.execute_reply": "2022-03-27T17:54:55.417353Z",
     "shell.execute_reply.started": "2022-03-27T17:54:45.810683Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3658109, [['陈品如', 0], ['陈祥旭', 0], ['陈晓', 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccnc = data_loader('data/data96861/ccnc.txt')\n",
    "len(ccnc), ccnc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-27T17:54:55.419383Z",
     "iopub.status.busy": "2022-03-27T17:54:55.418938Z",
     "iopub.status.idle": "2022-03-27T17:54:55.423613Z",
     "shell.execute_reply": "2022-03-27T17:54:55.423134Z",
     "shell.execute_reply.started": "2022-03-27T17:54:55.419358Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import seed, shuffle \n",
    "\n",
    "\n",
    "def train_dev_test_split(data, train=0.6, dev=0.2, test=0.2, seed_idx=5):\n",
    "    seed(seed_idx)\n",
    "    shuffle(data)\n",
    "    length = len(data)\n",
    "    boundary1 = round(length * train)\n",
    "    boundary2 = round(length * (train + dev))    \n",
    "    return data[:boundary1], data[boundary1: boundary2], data[boundary2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:54:55.424771Z",
     "iopub.status.busy": "2022-03-27T17:54:55.424529Z",
     "iopub.status.idle": "2022-03-27T17:54:59.696183Z",
     "shell.execute_reply": "2022-03-27T17:54:59.695582Z",
     "shell.execute_reply.started": "2022-03-27T17:54:55.424749Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2194865, 731622, 731622)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, dev_set, test_set = train_dev_test_split(ccnc)\n",
    "len(train_set), len(dev_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:54:59.698343Z",
     "iopub.status.busy": "2022-03-27T17:54:59.698097Z",
     "iopub.status.idle": "2022-03-27T17:55:02.407164Z",
     "shell.execute_reply": "2022-03-27T17:55:02.406404Z",
     "shell.execute_reply.started": "2022-03-27T17:54:59.698309Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import MapDataset\n",
    "from paddle.io import BatchSampler, DataLoader\n",
    "from paddlenlp.data import Pad, Stack, Tuple\n",
    "from paddlenlp.data import Vocab\n",
    "\n",
    "\n",
    "class TextVectorizer:\n",
    "     \n",
    "    def __init__(self, tokenizer=None):\n",
    "        self.tokenize = tokenizer\n",
    "        self.vocab_to_idx = None\n",
    "        self._V = None\n",
    "    \n",
    "    def build_vocab(self, text):\n",
    "        tokens = list(map(self.tokenize, text))\n",
    "        self._V = Vocab.build_vocab(tokens, unk_token='[UNK]', pad_token='[PAD]')\n",
    "        self.vocab_to_idx = self._V.token_to_idx\n",
    "        \n",
    "    def text_encoder(self, text):\n",
    "        if isinstance(text, list):\n",
    "            return [self(t) for t in text]\n",
    "        \n",
    "        tks = self.tokenize(text)\n",
    "        out = [self.vocab_to_idx[tk] for tk in tks]\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vocab_to_idx)\n",
    "\n",
    "    def __getitem__(self, w):\n",
    "        return self.vocab_to_idx[w]\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        if self.vocab_to_idx:\n",
    "            return self.text_encoder(text)\n",
    "        raise ValueError(\"No vocab is built!\")\n",
    "\n",
    "\n",
    "def example_converter(example, text_encoder, include_seq_len):\n",
    "    \n",
    "    text, label = example\n",
    "    encoded = text_encoder(text)\n",
    "    if include_seq_len:\n",
    "        text_len = len(encoded)\n",
    "        return encoded, text_len, label\n",
    "    return encoded, label\n",
    "\n",
    "\n",
    "def get_trans_fn(text_encoder, include_seq_len):\n",
    "    return lambda ex: example_converter(ex, text_encoder, include_seq_len)\n",
    "\n",
    "\n",
    "def get_batchify_fn(include_seq_len):\n",
    "    \n",
    "    if include_seq_len:\n",
    "        stack = [Stack(dtype=\"int64\")] * 2\n",
    "    else:\n",
    "        stack = [Stack(dtype=\"int64\")]\n",
    "    \n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=0),  \n",
    "        *stack\n",
    "    ): fn(samples)\n",
    "    \n",
    "    return batchify_fn\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, \n",
    "                      trans_fn, \n",
    "                      batchify_fn, \n",
    "                      batch_size=128, \n",
    "                      shuffle=True, \n",
    "                      sampler=BatchSampler):\n",
    "\n",
    "    if not isinstance(dataset, MapDataset):\n",
    "        dataset = MapDataset(dataset)\n",
    "        \n",
    "    dataset.map(trans_fn)\n",
    "    batch_sampler = sampler(dataset, \n",
    "                            shuffle=shuffle, \n",
    "                            batch_size=batch_size)\n",
    "    \n",
    "    dataloder = DataLoader(dataset, \n",
    "                           batch_sampler=batch_sampler, \n",
    "                           collate_fn=batchify_fn)\n",
    "    \n",
    "    return dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:55:02.408711Z",
     "iopub.status.busy": "2022-03-27T17:55:02.408394Z",
     "iopub.status.idle": "2022-03-27T17:55:17.896912Z",
     "shell.execute_reply": "2022-03-27T17:55:17.896306Z",
     "shell.execute_reply.started": "2022-03-27T17:55:02.408679Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocab (char): 6255\n"
     ]
    }
   ],
   "source": [
    "text = [t[0] for t in train_set]\n",
    "V = TextVectorizer(list)\n",
    "V.build_vocab(text)\n",
    "print(\"Number of vocab (char):\", len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:55:17.898417Z",
     "iopub.status.busy": "2022-03-27T17:55:17.897946Z",
     "iopub.status.idle": "2022-03-27T17:55:17.902792Z",
     "shell.execute_reply": "2022-03-27T17:55:17.902154Z",
     "shell.execute_reply.started": "2022-03-27T17:55:17.898389Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "include_seq_len = True; batch_size = 1024\n",
    "trans_fn = get_trans_fn(V, include_seq_len=include_seq_len)\n",
    "batchify_fn = get_batchify_fn(include_seq_len=include_seq_len)\n",
    "train_loader = create_dataloader(train_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "dev_loader = create_dataloader(dev_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "test_loader = create_dataloader(test_set, trans_fn, batchify_fn, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:55:17.904017Z",
     "iopub.status.busy": "2022-03-27T17:55:17.903609Z",
     "iopub.status.idle": "2022-03-27T17:55:17.911778Z",
     "shell.execute_reply": "2022-03-27T17:55:17.911256Z",
     "shell.execute_reply.started": "2022-03-27T17:55:17.903993Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle, paddlenlp\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "\n",
    "class LSTM(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_classes,\n",
    "                 emb_dim=30,\n",
    "                 padding_idx=0,\n",
    "                 lstm_hidden_size=15,\n",
    "                 direction='forward',\n",
    "                 lstm_layers=1,\n",
    "                 dropout_rate=0.0,\n",
    "                 pooling_type=None,\n",
    "                 fc_hidden_size=96):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedder = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=emb_dim,\n",
    "            padding_idx=padding_idx)\n",
    "\n",
    "        self.lstm_encoder = paddlenlp.seq2vec.LSTMEncoder(\n",
    "            emb_dim,\n",
    "            lstm_hidden_size,\n",
    "            num_layers=lstm_layers,\n",
    "            direction=direction,\n",
    "            dropout=dropout_rate,\n",
    "            pooling_type=pooling_type)\n",
    "\n",
    "        self.fc = nn.Linear(self.lstm_encoder.get_output_dim(), fc_hidden_size)\n",
    "        self.output_layer = nn.Linear(fc_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, text, seq_len):\n",
    "        embedded_text = self.embedder(text)\n",
    "        text_repr = self.lstm_encoder(embedded_text, sequence_length=seq_len)\n",
    "        fc_out = paddle.tanh(self.fc(text_repr))\n",
    "        logits = self.output_layer(fc_out)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def get_model(model):\n",
    "    model = paddle.Model(model)\n",
    "    optimizer = paddle.optimizer.Adam(\n",
    "    parameters=model.parameters(), learning_rate=5e-4)\n",
    "    criterion = paddle.nn.CrossEntropyLoss()\n",
    "    metric = paddle.metric.Accuracy()\n",
    "    model.prepare(optimizer, criterion, metric)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:55:17.912876Z",
     "iopub.status.busy": "2022-03-27T17:55:17.912627Z",
     "iopub.status.idle": "2022-03-27T17:55:22.622577Z",
     "shell.execute_reply": "2022-03-27T17:55:22.621820Z",
     "shell.execute_reply.started": "2022-03-27T17:55:17.912854Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0328 01:55:17.914574  4710 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0328 01:55:17.919216  4710 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(len(V), 3)\n",
    "model = get_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:55:22.624156Z",
     "iopub.status.busy": "2022-03-27T17:55:22.623661Z",
     "iopub.status.idle": "2022-03-27T18:01:14.309512Z",
     "shell.execute_reply": "2022-03-27T18:01:14.308932Z",
     "shell.execute_reply.started": "2022-03-27T17:55:22.624125Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/10\n",
      "step 1000/2144 - loss: 0.1340 - acc: 0.8981 - 18ms/step\n",
      "step 2000/2144 - loss: 0.1084 - acc: 0.9249 - 18ms/step\n",
      "step 2144/2144 - loss: 0.1210 - acc: 0.9268 - 18ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.1480 - acc: 0.9541 - 16ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 2/10\n",
      "step 1000/2144 - loss: 0.1054 - acc: 0.9557 - 18ms/step\n",
      "step 2000/2144 - loss: 0.1136 - acc: 0.9565 - 18ms/step\n",
      "step 2144/2144 - loss: 0.1384 - acc: 0.9567 - 18ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0894 - acc: 0.9590 - 15ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 3/10\n",
      "step 1000/2144 - loss: 0.1169 - acc: 0.9603 - 17ms/step\n",
      "step 2000/2144 - loss: 0.0797 - acc: 0.9609 - 18ms/step\n",
      "step 2144/2144 - loss: 0.1184 - acc: 0.9610 - 18ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.1055 - acc: 0.9618 - 15ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 4/10\n",
      "step 1000/2144 - loss: 0.0901 - acc: 0.9630 - 17ms/step\n",
      "step 2000/2144 - loss: 0.0934 - acc: 0.9633 - 19ms/step\n",
      "step 2144/2144 - loss: 0.0929 - acc: 0.9633 - 19ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0530 - acc: 0.9636 - 17ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 5/10\n",
      "step 1000/2144 - loss: 0.0905 - acc: 0.9645 - 18ms/step\n",
      "step 2000/2144 - loss: 0.0837 - acc: 0.9647 - 19ms/step\n",
      "step 2144/2144 - loss: 0.1212 - acc: 0.9647 - 19ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.1004 - acc: 0.9649 - 16ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 6/10\n",
      "step 1000/2144 - loss: 0.0806 - acc: 0.9658 - 18ms/step\n",
      "step 2000/2144 - loss: 0.0793 - acc: 0.9659 - 18ms/step\n",
      "step 2144/2144 - loss: 0.0707 - acc: 0.9660 - 18ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0715 - acc: 0.9656 - 16ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 7/10\n",
      "step 1000/2144 - loss: 0.0706 - acc: 0.9672 - 18ms/step\n",
      "step 2000/2144 - loss: 0.0899 - acc: 0.9672 - 19ms/step\n",
      "step 2144/2144 - loss: 0.0974 - acc: 0.9672 - 19ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0749 - acc: 0.9665 - 15ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 7: Early stopping.\n"
     ]
    }
   ],
   "source": [
    "from paddle.callbacks import EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(patience=3)\n",
    "\n",
    "model.fit(train_loader, dev_loader, epochs=10, verbose=2, log_freq=1000, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T18:01:14.310967Z",
     "iopub.status.busy": "2022-03-27T18:01:14.310494Z",
     "iopub.status.idle": "2022-03-27T18:01:14.348302Z",
     "shell.execute_reply": "2022-03-27T18:01:14.347517Z",
     "shell.execute_reply.started": "2022-03-27T18:01:14.310938Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(\"ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T18:01:14.350518Z",
     "iopub.status.busy": "2022-03-27T18:01:14.349862Z",
     "iopub.status.idle": "2022-03-27T18:01:25.075936Z",
     "shell.execute_reply": "2022-03-27T18:01:25.075254Z",
     "shell.execute_reply.started": "2022-03-27T18:01:14.350464Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step  10/715 - loss: 0.0853 - acc: 0.9674 - 21ms/step\n",
      "step  20/715 - loss: 0.0747 - acc: 0.9680 - 18ms/step\n",
      "step  30/715 - loss: 0.0853 - acc: 0.9667 - 17ms/step\n",
      "step  40/715 - loss: 0.0783 - acc: 0.9660 - 16ms/step\n",
      "step  50/715 - loss: 0.0853 - acc: 0.9663 - 16ms/step\n",
      "step  60/715 - loss: 0.0791 - acc: 0.9666 - 16ms/step\n",
      "step  70/715 - loss: 0.0811 - acc: 0.9665 - 16ms/step\n",
      "step  80/715 - loss: 0.0813 - acc: 0.9661 - 16ms/step\n",
      "step  90/715 - loss: 0.0643 - acc: 0.9663 - 15ms/step\n",
      "step 100/715 - loss: 0.0768 - acc: 0.9663 - 15ms/step\n",
      "step 110/715 - loss: 0.0953 - acc: 0.9662 - 15ms/step\n",
      "step 120/715 - loss: 0.0723 - acc: 0.9662 - 15ms/step\n",
      "step 130/715 - loss: 0.0931 - acc: 0.9662 - 15ms/step\n",
      "step 140/715 - loss: 0.0799 - acc: 0.9663 - 15ms/step\n",
      "step 150/715 - loss: 0.0676 - acc: 0.9665 - 15ms/step\n",
      "step 160/715 - loss: 0.0650 - acc: 0.9663 - 15ms/step\n",
      "step 170/715 - loss: 0.0660 - acc: 0.9665 - 15ms/step\n",
      "step 180/715 - loss: 0.0825 - acc: 0.9663 - 15ms/step\n",
      "step 190/715 - loss: 0.0846 - acc: 0.9661 - 15ms/step\n",
      "step 200/715 - loss: 0.0930 - acc: 0.9660 - 15ms/step\n",
      "step 210/715 - loss: 0.0861 - acc: 0.9660 - 15ms/step\n",
      "step 220/715 - loss: 0.0905 - acc: 0.9660 - 15ms/step\n",
      "step 230/715 - loss: 0.0696 - acc: 0.9659 - 15ms/step\n",
      "step 240/715 - loss: 0.0661 - acc: 0.9659 - 15ms/step\n",
      "step 250/715 - loss: 0.0872 - acc: 0.9660 - 15ms/step\n",
      "step 260/715 - loss: 0.0684 - acc: 0.9660 - 15ms/step\n",
      "step 270/715 - loss: 0.0947 - acc: 0.9660 - 15ms/step\n",
      "step 280/715 - loss: 0.0941 - acc: 0.9660 - 15ms/step\n",
      "step 290/715 - loss: 0.0828 - acc: 0.9661 - 15ms/step\n",
      "step 300/715 - loss: 0.0919 - acc: 0.9660 - 15ms/step\n",
      "step 310/715 - loss: 0.0839 - acc: 0.9660 - 15ms/step\n",
      "step 320/715 - loss: 0.0863 - acc: 0.9660 - 15ms/step\n",
      "step 330/715 - loss: 0.0548 - acc: 0.9660 - 15ms/step\n",
      "step 340/715 - loss: 0.0940 - acc: 0.9660 - 15ms/step\n",
      "step 350/715 - loss: 0.1116 - acc: 0.9660 - 15ms/step\n",
      "step 360/715 - loss: 0.0819 - acc: 0.9660 - 15ms/step\n",
      "step 370/715 - loss: 0.0782 - acc: 0.9659 - 15ms/step\n",
      "step 380/715 - loss: 0.0848 - acc: 0.9660 - 15ms/step\n",
      "step 390/715 - loss: 0.0778 - acc: 0.9659 - 15ms/step\n",
      "step 400/715 - loss: 0.0795 - acc: 0.9660 - 15ms/step\n",
      "step 410/715 - loss: 0.0966 - acc: 0.9659 - 15ms/step\n",
      "step 420/715 - loss: 0.0796 - acc: 0.9659 - 15ms/step\n",
      "step 430/715 - loss: 0.0760 - acc: 0.9659 - 15ms/step\n",
      "step 440/715 - loss: 0.0769 - acc: 0.9660 - 15ms/step\n",
      "step 450/715 - loss: 0.0760 - acc: 0.9660 - 15ms/step\n",
      "step 460/715 - loss: 0.0703 - acc: 0.9660 - 15ms/step\n",
      "step 470/715 - loss: 0.0757 - acc: 0.9660 - 15ms/step\n",
      "step 480/715 - loss: 0.0862 - acc: 0.9660 - 15ms/step\n",
      "step 490/715 - loss: 0.0746 - acc: 0.9659 - 15ms/step\n",
      "step 500/715 - loss: 0.0719 - acc: 0.9659 - 15ms/step\n",
      "step 510/715 - loss: 0.0693 - acc: 0.9658 - 15ms/step\n",
      "step 520/715 - loss: 0.0892 - acc: 0.9658 - 15ms/step\n",
      "step 530/715 - loss: 0.0783 - acc: 0.9658 - 15ms/step\n",
      "step 540/715 - loss: 0.0733 - acc: 0.9659 - 15ms/step\n",
      "step 550/715 - loss: 0.0700 - acc: 0.9659 - 15ms/step\n",
      "step 560/715 - loss: 0.0758 - acc: 0.9659 - 15ms/step\n",
      "step 570/715 - loss: 0.0792 - acc: 0.9659 - 15ms/step\n",
      "step 580/715 - loss: 0.0944 - acc: 0.9659 - 15ms/step\n",
      "step 590/715 - loss: 0.0848 - acc: 0.9659 - 15ms/step\n",
      "step 600/715 - loss: 0.0665 - acc: 0.9659 - 15ms/step\n",
      "step 610/715 - loss: 0.0713 - acc: 0.9660 - 15ms/step\n",
      "step 620/715 - loss: 0.0600 - acc: 0.9660 - 15ms/step\n",
      "step 630/715 - loss: 0.0778 - acc: 0.9660 - 15ms/step\n",
      "step 640/715 - loss: 0.0620 - acc: 0.9661 - 15ms/step\n",
      "step 650/715 - loss: 0.0885 - acc: 0.9661 - 15ms/step\n",
      "step 660/715 - loss: 0.1009 - acc: 0.9661 - 15ms/step\n",
      "step 670/715 - loss: 0.0799 - acc: 0.9661 - 15ms/step\n",
      "step 680/715 - loss: 0.0857 - acc: 0.9660 - 15ms/step\n",
      "step 690/715 - loss: 0.0880 - acc: 0.9660 - 15ms/step\n",
      "step 700/715 - loss: 0.0808 - acc: 0.9660 - 15ms/step\n",
      "step 710/715 - loss: 0.0882 - acc: 0.9660 - 15ms/step\n",
      "step 715/715 - loss: 0.0755 - acc: 0.9660 - 15ms/step\n",
      "Eval samples: 731622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.075469315], 'acc': 0.9660179710287553}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
