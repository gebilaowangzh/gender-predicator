{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-30T17:25:35.892503Z",
     "iopub.status.busy": "2022-03-30T17:25:35.891821Z",
     "iopub.status.idle": "2022-03-30T17:25:35.898572Z",
     "shell.execute_reply": "2022-03-30T17:25:35.897985Z",
     "shell.execute_reply.started": "2022-03-30T17:25:35.892471Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relabel(g, reverse=False):\n",
    "    if reverse:\n",
    "        return {0: 'M', 1: 'F', 2: 'U'}[g]\n",
    "    return {'M': 0, 'F': 1, 'U': 2}[g]\n",
    "\n",
    "\n",
    "def data_loader(filepath, num_row_skip=1):\n",
    "    def readFile(path):\n",
    "        f = open(path, 'r')\n",
    "        for _ in range(num_row_skip):\n",
    "            next(f)\n",
    "        out = []\n",
    "        for line in f:\n",
    "            line = line.split('\\t')\n",
    "            out.append([line[-2], relabel(line[-1].strip())])\n",
    "        return out\n",
    "    \n",
    "    if isinstance(filepath, str):\n",
    "        return readFile(filepath)\n",
    "    elif isinstance(filepath, list):\n",
    "        return [readFile(path) for path in filepath]\n",
    "    else:\n",
    "         raise TypeError('filepath must be either a str or a list.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-30T17:25:35.900122Z",
     "iopub.status.busy": "2022-03-30T17:25:35.899637Z",
     "iopub.status.idle": "2022-03-30T17:25:44.493179Z",
     "shell.execute_reply": "2022-03-30T17:25:44.492395Z",
     "shell.execute_reply.started": "2022-03-30T17:25:35.900094Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3658109, [['陈品如', 0], ['陈祥旭', 0], ['陈晓', 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccnc = data_loader('data/data96861/ccnc.txt')\n",
    "len(ccnc), ccnc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-30T17:25:44.494395Z",
     "iopub.status.busy": "2022-03-30T17:25:44.494063Z",
     "iopub.status.idle": "2022-03-30T17:25:44.498623Z",
     "shell.execute_reply": "2022-03-30T17:25:44.498153Z",
     "shell.execute_reply.started": "2022-03-30T17:25:44.494361Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import seed, shuffle \n",
    "\n",
    "\n",
    "def train_dev_test_split(data, train=0.6, dev=0.2, test=0.2, seed_idx=5):\n",
    "    seed(seed_idx)\n",
    "    shuffle(data)\n",
    "    length = len(data)\n",
    "    boundary1 = round(length * train)\n",
    "    boundary2 = round(length * (train + dev))    \n",
    "    return data[:boundary1], data[boundary1: boundary2], data[boundary2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:25:44.500211Z",
     "iopub.status.busy": "2022-03-30T17:25:44.499760Z",
     "iopub.status.idle": "2022-03-30T17:25:49.134129Z",
     "shell.execute_reply": "2022-03-30T17:25:49.133604Z",
     "shell.execute_reply.started": "2022-03-30T17:25:44.500187Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2194865, 731622, 731622)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, dev_set, test_set = train_dev_test_split(ccnc)\n",
    "len(train_set), len(dev_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:25:49.135694Z",
     "iopub.status.busy": "2022-03-30T17:25:49.135074Z",
     "iopub.status.idle": "2022-03-30T17:25:51.567934Z",
     "shell.execute_reply": "2022-03-30T17:25:51.566996Z",
     "shell.execute_reply.started": "2022-03-30T17:25:49.135668Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import MapDataset\n",
    "from paddle.io import BatchSampler, DataLoader\n",
    "from paddlenlp.data import Pad, Stack, Tuple\n",
    "from paddlenlp.data import Vocab\n",
    "\n",
    "\n",
    "class TextVectorizer:\n",
    "     \n",
    "    def __init__(self, tokenizer=None):\n",
    "        self.tokenize = tokenizer\n",
    "        self.vocab_to_idx = None\n",
    "        self._V = None\n",
    "    \n",
    "    def build_vocab(self, text):\n",
    "        tokens = list(map(self.tokenize, text))\n",
    "        self._V = Vocab.build_vocab(tokens, unk_token='[UNK]', pad_token='[PAD]')\n",
    "        self.vocab_to_idx = self._V.token_to_idx\n",
    "        \n",
    "    def text_encoder(self, text):\n",
    "        if isinstance(text, list):\n",
    "            return [self(t) for t in text]\n",
    "        \n",
    "        tks = self.tokenize(text)\n",
    "        out = [self.vocab_to_idx[tk] for tk in tks]\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vocab_to_idx)\n",
    "\n",
    "    def __getitem__(self, w):\n",
    "        return self.vocab_to_idx[w]\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        if self.vocab_to_idx:\n",
    "            return self.text_encoder(text)\n",
    "        raise ValueError(\"No vocab is built!\")\n",
    "\n",
    "\n",
    "def example_converter(example, text_encoder, include_seq_len):\n",
    "    \n",
    "    text, label = example\n",
    "    encoded = text_encoder(text)\n",
    "    if include_seq_len:\n",
    "        text_len = len(encoded)\n",
    "        return encoded, text_len, label\n",
    "    return encoded, label\n",
    "\n",
    "\n",
    "def get_trans_fn(text_encoder, include_seq_len):\n",
    "    return lambda ex: example_converter(ex, text_encoder, include_seq_len)\n",
    "\n",
    "\n",
    "def get_batchify_fn(include_seq_len):\n",
    "    \n",
    "    if include_seq_len:\n",
    "        stack = [Stack(dtype=\"int64\")] * 2\n",
    "    else:\n",
    "        stack = [Stack(dtype=\"int64\")]\n",
    "    \n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=0),  \n",
    "        *stack\n",
    "    ): fn(samples)\n",
    "    \n",
    "    return batchify_fn\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, \n",
    "                      trans_fn, \n",
    "                      batchify_fn, \n",
    "                      batch_size=128, \n",
    "                      shuffle=True, \n",
    "                      sampler=BatchSampler):\n",
    "\n",
    "    if not isinstance(dataset, MapDataset):\n",
    "        dataset = MapDataset(dataset)\n",
    "        \n",
    "    dataset.map(trans_fn)\n",
    "    batch_sampler = sampler(dataset, \n",
    "                            shuffle=shuffle, \n",
    "                            batch_size=batch_size)\n",
    "    \n",
    "    dataloder = DataLoader(dataset, \n",
    "                           batch_sampler=batch_sampler, \n",
    "                           collate_fn=batchify_fn)\n",
    "    \n",
    "    return dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:25:51.569550Z",
     "iopub.status.busy": "2022-03-30T17:25:51.569121Z",
     "iopub.status.idle": "2022-03-30T17:26:04.842718Z",
     "shell.execute_reply": "2022-03-30T17:26:04.842137Z",
     "shell.execute_reply.started": "2022-03-30T17:25:51.569519Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocab (char): 6255\n"
     ]
    }
   ],
   "source": [
    "text = [t[0] for t in train_set]\n",
    "V = TextVectorizer(list)\n",
    "V.build_vocab(text)\n",
    "print(\"Number of vocab (char):\", len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:26:04.844068Z",
     "iopub.status.busy": "2022-03-30T17:26:04.843641Z",
     "iopub.status.idle": "2022-03-30T17:26:04.848454Z",
     "shell.execute_reply": "2022-03-30T17:26:04.847954Z",
     "shell.execute_reply.started": "2022-03-30T17:26:04.844042Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "include_seq_len = False; batch_size = 1024\n",
    "trans_fn = get_trans_fn(V, include_seq_len=include_seq_len)\n",
    "batchify_fn = get_batchify_fn(include_seq_len=include_seq_len)\n",
    "train_loader = create_dataloader(train_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "dev_loader = create_dataloader(dev_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "test_loader = create_dataloader(test_set, trans_fn, batchify_fn, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:26:37.399156Z",
     "iopub.status.busy": "2022-03-30T17:26:37.398114Z",
     "iopub.status.idle": "2022-03-30T17:26:37.408754Z",
     "shell.execute_reply": "2022-03-30T17:26:37.408075Z",
     "shell.execute_reply.started": "2022-03-30T17:26:37.399109Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle \n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "\n",
    "class LogisticRegression(nn.Layer):\n",
    "\n",
    "    def __init__(self, \n",
    "                vocab_size, \n",
    "                output_dim,\n",
    "                embedding_dim=100,\n",
    "                padding_idx=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        \n",
    "        self.dense = nn.Linear(embedding_dim, output_dim)\n",
    "\n",
    "    def encoder(self, embd):\n",
    "        return embd.sum(axis=1)\n",
    "\n",
    "    def forward(self, text_ids): \n",
    "        text_embd = self.embedding(text_ids)\n",
    "        encoded = self.encoder(text_embd)\n",
    "        out_logits = self.dense(encoded)\n",
    "        return out_logits\n",
    "\n",
    "\n",
    "def get_model(model):\n",
    "    model = paddle.Model(model)\n",
    "    optimizer = paddle.optimizer.Adam(\n",
    "    parameters=model.parameters(), learning_rate=5e-4)\n",
    "    criterion = paddle.nn.CrossEntropyLoss()\n",
    "    metric = paddle.metric.Accuracy()\n",
    "    model.prepare(optimizer, criterion, metric)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:26:39.926029Z",
     "iopub.status.busy": "2022-03-30T17:26:39.925094Z",
     "iopub.status.idle": "2022-03-30T17:26:39.940992Z",
     "shell.execute_reply": "2022-03-30T17:26:39.940346Z",
     "shell.execute_reply.started": "2022-03-30T17:26:39.925996Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(len(V), 3)\n",
    "model = get_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:26:40.541016Z",
     "iopub.status.busy": "2022-03-30T17:26:40.540137Z",
     "iopub.status.idle": "2022-03-30T17:30:40.641676Z",
     "shell.execute_reply": "2022-03-30T17:30:40.640934Z",
     "shell.execute_reply.started": "2022-03-30T17:26:40.540973Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/10\n",
      "step 1000/2144 - loss: 0.2021 - acc: 0.9149 - 16ms/step\n",
      "step 2000/2144 - loss: 0.1605 - acc: 0.9241 - 16ms/step\n",
      "step 2144/2144 - loss: 0.1666 - acc: 0.9247 - 16ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.1979 - acc: 0.9343 - 11ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 2/10\n",
      "step 1000/2144 - loss: 0.1668 - acc: 0.9341 - 16ms/step\n",
      "step 2000/2144 - loss: 0.1985 - acc: 0.9346 - 16ms/step\n",
      "step 2144/2144 - loss: 0.1399 - acc: 0.9347 - 16ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.1289 - acc: 0.9351 - 12ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 3/10\n",
      "step 1000/2144 - loss: 0.1950 - acc: 0.9353 - 17ms/step\n",
      "step 2000/2144 - loss: 0.1659 - acc: 0.9352 - 16ms/step\n",
      "step 2144/2144 - loss: 0.1240 - acc: 0.9353 - 17ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.1834 - acc: 0.9354 - 15ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 4/10\n",
      "step 1000/2144 - loss: 0.1649 - acc: 0.9352 - 20ms/step\n",
      "step 2000/2144 - loss: 0.1602 - acc: 0.9357 - 20ms/step\n",
      "step 2144/2144 - loss: 0.2387 - acc: 0.9356 - 20ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.1496 - acc: 0.9355 - 18ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 5/10\n",
      "step 1000/2144 - loss: 0.1498 - acc: 0.9357 - 21ms/step\n",
      "step 2000/2144 - loss: 0.1937 - acc: 0.9359 - 21ms/step\n",
      "step 2144/2144 - loss: 0.2477 - acc: 0.9358 - 20ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.1569 - acc: 0.9357 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 5: Early stopping.\n"
     ]
    }
   ],
   "source": [
    "from paddle.callbacks import EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(patience=3)\n",
    "\n",
    "model.fit(train_loader, dev_loader, epochs=10, verbose=2, log_freq=1000, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:31:13.969860Z",
     "iopub.status.busy": "2022-03-30T17:31:13.969095Z",
     "iopub.status.idle": "2022-03-30T17:31:24.476263Z",
     "shell.execute_reply": "2022-03-30T17:31:24.475616Z",
     "shell.execute_reply.started": "2022-03-30T17:31:13.969826Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step  10/715 - loss: 0.1996 - acc: 0.9375 - 21ms/step\n",
      "step  20/715 - loss: 0.1589 - acc: 0.9361 - 17ms/step\n",
      "step  30/715 - loss: 0.1965 - acc: 0.9348 - 16ms/step\n",
      "step  40/715 - loss: 0.1495 - acc: 0.9360 - 16ms/step\n",
      "step  50/715 - loss: 0.1826 - acc: 0.9363 - 15ms/step\n",
      "step  60/715 - loss: 0.1599 - acc: 0.9366 - 15ms/step\n",
      "step  70/715 - loss: 0.1661 - acc: 0.9363 - 15ms/step\n",
      "step  80/715 - loss: 0.1792 - acc: 0.9359 - 15ms/step\n",
      "step  90/715 - loss: 0.1491 - acc: 0.9354 - 15ms/step\n",
      "step 100/715 - loss: 0.1782 - acc: 0.9354 - 15ms/step\n",
      "step 110/715 - loss: 0.1814 - acc: 0.9354 - 15ms/step\n",
      "step 120/715 - loss: 0.1928 - acc: 0.9356 - 15ms/step\n",
      "step 130/715 - loss: 0.1963 - acc: 0.9356 - 15ms/step\n",
      "step 140/715 - loss: 0.1599 - acc: 0.9358 - 15ms/step\n",
      "step 150/715 - loss: 0.1554 - acc: 0.9358 - 15ms/step\n",
      "step 160/715 - loss: 0.1588 - acc: 0.9357 - 15ms/step\n",
      "step 170/715 - loss: 0.1512 - acc: 0.9358 - 15ms/step\n",
      "step 180/715 - loss: 0.2028 - acc: 0.9357 - 15ms/step\n",
      "step 190/715 - loss: 0.1811 - acc: 0.9357 - 15ms/step\n",
      "step 200/715 - loss: 0.2170 - acc: 0.9357 - 15ms/step\n",
      "step 210/715 - loss: 0.2116 - acc: 0.9356 - 15ms/step\n",
      "step 220/715 - loss: 0.1919 - acc: 0.9353 - 15ms/step\n",
      "step 230/715 - loss: 0.1720 - acc: 0.9352 - 15ms/step\n",
      "step 240/715 - loss: 0.1668 - acc: 0.9354 - 15ms/step\n",
      "step 250/715 - loss: 0.1651 - acc: 0.9354 - 15ms/step\n",
      "step 260/715 - loss: 0.1694 - acc: 0.9354 - 15ms/step\n",
      "step 270/715 - loss: 0.2035 - acc: 0.9354 - 15ms/step\n",
      "step 280/715 - loss: 0.1941 - acc: 0.9353 - 15ms/step\n",
      "step 290/715 - loss: 0.1734 - acc: 0.9354 - 15ms/step\n",
      "step 300/715 - loss: 0.1900 - acc: 0.9354 - 15ms/step\n",
      "step 310/715 - loss: 0.1570 - acc: 0.9354 - 15ms/step\n",
      "step 320/715 - loss: 0.1965 - acc: 0.9355 - 15ms/step\n",
      "step 330/715 - loss: 0.1671 - acc: 0.9355 - 15ms/step\n",
      "step 340/715 - loss: 0.2175 - acc: 0.9355 - 15ms/step\n",
      "step 350/715 - loss: 0.1885 - acc: 0.9355 - 15ms/step\n",
      "step 360/715 - loss: 0.1674 - acc: 0.9355 - 15ms/step\n",
      "step 370/715 - loss: 0.1607 - acc: 0.9354 - 15ms/step\n",
      "step 380/715 - loss: 0.1688 - acc: 0.9354 - 15ms/step\n",
      "step 390/715 - loss: 0.1868 - acc: 0.9353 - 15ms/step\n",
      "step 400/715 - loss: 0.1602 - acc: 0.9354 - 15ms/step\n",
      "step 410/715 - loss: 0.1881 - acc: 0.9355 - 15ms/step\n",
      "step 420/715 - loss: 0.1648 - acc: 0.9354 - 15ms/step\n",
      "step 430/715 - loss: 0.1703 - acc: 0.9354 - 15ms/step\n",
      "step 440/715 - loss: 0.1881 - acc: 0.9353 - 15ms/step\n",
      "step 450/715 - loss: 0.1694 - acc: 0.9354 - 15ms/step\n",
      "step 460/715 - loss: 0.1538 - acc: 0.9354 - 15ms/step\n",
      "step 470/715 - loss: 0.1641 - acc: 0.9355 - 15ms/step\n",
      "step 480/715 - loss: 0.1572 - acc: 0.9354 - 15ms/step\n",
      "step 490/715 - loss: 0.1681 - acc: 0.9354 - 15ms/step\n",
      "step 500/715 - loss: 0.1520 - acc: 0.9353 - 15ms/step\n",
      "step 510/715 - loss: 0.1592 - acc: 0.9352 - 15ms/step\n",
      "step 520/715 - loss: 0.1794 - acc: 0.9352 - 15ms/step\n",
      "step 530/715 - loss: 0.1705 - acc: 0.9352 - 15ms/step\n",
      "step 540/715 - loss: 0.1689 - acc: 0.9352 - 15ms/step\n",
      "step 550/715 - loss: 0.1622 - acc: 0.9352 - 15ms/step\n",
      "step 560/715 - loss: 0.1576 - acc: 0.9352 - 15ms/step\n",
      "step 570/715 - loss: 0.1995 - acc: 0.9352 - 15ms/step\n",
      "step 580/715 - loss: 0.1817 - acc: 0.9352 - 15ms/step\n",
      "step 590/715 - loss: 0.1829 - acc: 0.9352 - 15ms/step\n",
      "step 600/715 - loss: 0.1831 - acc: 0.9352 - 15ms/step\n",
      "step 610/715 - loss: 0.1753 - acc: 0.9352 - 15ms/step\n",
      "step 620/715 - loss: 0.1826 - acc: 0.9351 - 15ms/step\n",
      "step 630/715 - loss: 0.1646 - acc: 0.9352 - 15ms/step\n",
      "step 640/715 - loss: 0.1756 - acc: 0.9351 - 15ms/step\n",
      "step 650/715 - loss: 0.1811 - acc: 0.9352 - 15ms/step\n",
      "step 660/715 - loss: 0.2096 - acc: 0.9352 - 15ms/step\n",
      "step 670/715 - loss: 0.1774 - acc: 0.9352 - 15ms/step\n",
      "step 680/715 - loss: 0.1976 - acc: 0.9351 - 15ms/step\n",
      "step 690/715 - loss: 0.1922 - acc: 0.9352 - 15ms/step\n",
      "step 700/715 - loss: 0.1914 - acc: 0.9352 - 15ms/step\n",
      "step 710/715 - loss: 0.1863 - acc: 0.9352 - 15ms/step\n",
      "step 715/715 - loss: 0.1742 - acc: 0.9352 - 15ms/step\n",
      "Eval samples: 731622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.17419836], 'acc': 0.9351523054254792}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
