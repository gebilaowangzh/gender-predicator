{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-27T17:31:10.142966Z",
     "iopub.status.busy": "2022-03-27T17:31:10.142792Z",
     "iopub.status.idle": "2022-03-27T17:31:10.149785Z",
     "shell.execute_reply": "2022-03-27T17:31:10.149053Z",
     "shell.execute_reply.started": "2022-03-27T17:31:10.142938Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relabel(g, reverse=False):\n",
    "    if reverse:\n",
    "        return {0: 'M', 1: 'F', 2: 'U'}[g]\n",
    "    return {'M': 0, 'F': 1, 'U': 2}[g]\n",
    "\n",
    "\n",
    "def data_loader(filepath, num_row_skip=1):\n",
    "    def readFile(path):\n",
    "        f = open(path, 'r')\n",
    "        for _ in range(num_row_skip):\n",
    "            next(f)\n",
    "        out = []\n",
    "        for line in f:\n",
    "            line = line.split('\\t')\n",
    "            out.append([line[-2], relabel(line[-1].strip())])\n",
    "        return out\n",
    "    \n",
    "    if isinstance(filepath, str):\n",
    "        return readFile(filepath)\n",
    "    elif isinstance(filepath, list):\n",
    "        return [readFile(path) for path in filepath]\n",
    "    else:\n",
    "         raise TypeError('filepath must be either a str or a list.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-27T17:31:10.186986Z",
     "iopub.status.busy": "2022-03-27T17:31:10.186509Z",
     "iopub.status.idle": "2022-03-27T17:31:20.221440Z",
     "shell.execute_reply": "2022-03-27T17:31:20.220878Z",
     "shell.execute_reply.started": "2022-03-27T17:31:10.186949Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3658109, [['陈品如', 0], ['陈祥旭', 0], ['陈晓', 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccnc = data_loader('data/data96861/ccnc.txt')\n",
    "len(ccnc), ccnc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-27T17:31:20.223479Z",
     "iopub.status.busy": "2022-03-27T17:31:20.223045Z",
     "iopub.status.idle": "2022-03-27T17:31:20.228451Z",
     "shell.execute_reply": "2022-03-27T17:31:20.227940Z",
     "shell.execute_reply.started": "2022-03-27T17:31:20.223453Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import seed, shuffle \n",
    "\n",
    "\n",
    "def train_dev_test_split(data, train=0.6, dev=0.2, test=0.2, seed_idx=5):\n",
    "    seed(seed_idx)\n",
    "    shuffle(data)\n",
    "    length = len(data)\n",
    "    boundary1 = round(length * train)\n",
    "    boundary2 = round(length * (train + dev))    \n",
    "    return data[:boundary1], data[boundary1: boundary2], data[boundary2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:31:20.229777Z",
     "iopub.status.busy": "2022-03-27T17:31:20.229522Z",
     "iopub.status.idle": "2022-03-27T17:31:25.854446Z",
     "shell.execute_reply": "2022-03-27T17:31:25.853819Z",
     "shell.execute_reply.started": "2022-03-27T17:31:20.229726Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2194865, 731622, 731622)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, dev_set, test_set = train_dev_test_split(ccnc)\n",
    "len(train_set), len(dev_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:31:25.856271Z",
     "iopub.status.busy": "2022-03-27T17:31:25.855686Z",
     "iopub.status.idle": "2022-03-27T17:31:28.632591Z",
     "shell.execute_reply": "2022-03-27T17:31:28.631786Z",
     "shell.execute_reply.started": "2022-03-27T17:31:25.856238Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import MapDataset\n",
    "from paddle.io import BatchSampler, DataLoader\n",
    "from paddlenlp.data import Pad, Stack, Tuple\n",
    "from paddlenlp.data import Vocab\n",
    "\n",
    "\n",
    "class TextVectorizer:\n",
    "     \n",
    "    def __init__(self, tokenizer=None):\n",
    "        self.tokenize = tokenizer\n",
    "        self.vocab_to_idx = None\n",
    "        self._V = None\n",
    "    \n",
    "    def build_vocab(self, text):\n",
    "        tokens = list(map(self.tokenize, text))\n",
    "        self._V = Vocab.build_vocab(tokens, unk_token='[UNK]', pad_token='[PAD]')\n",
    "        self.vocab_to_idx = self._V.token_to_idx\n",
    "        \n",
    "    def text_encoder(self, text):\n",
    "        if isinstance(text, list):\n",
    "            return [self(t) for t in text]\n",
    "        \n",
    "        tks = self.tokenize(text)\n",
    "        out = [self.vocab_to_idx[tk] for tk in tks]\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vocab_to_idx)\n",
    "\n",
    "    def __getitem__(self, w):\n",
    "        return self.vocab_to_idx[w]\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        if self.vocab_to_idx:\n",
    "            return self.text_encoder(text)\n",
    "        raise ValueError(\"No vocab is built!\")\n",
    "\n",
    "\n",
    "def example_converter(example, text_encoder, include_seq_len):\n",
    "    \n",
    "    text, label = example\n",
    "    encoded = text_encoder(text)\n",
    "    if include_seq_len:\n",
    "        text_len = len(encoded)\n",
    "        return encoded, text_len, label\n",
    "    return encoded, label\n",
    "\n",
    "\n",
    "def get_trans_fn(text_encoder, include_seq_len):\n",
    "    return lambda ex: example_converter(ex, text_encoder, include_seq_len)\n",
    "\n",
    "\n",
    "def get_batchify_fn(include_seq_len):\n",
    "    \n",
    "    if include_seq_len:\n",
    "        stack = [Stack(dtype=\"int64\")] * 2\n",
    "    else:\n",
    "        stack = [Stack(dtype=\"int64\")]\n",
    "    \n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=0),  \n",
    "        *stack\n",
    "    ): fn(samples)\n",
    "    \n",
    "    return batchify_fn\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, \n",
    "                      trans_fn, \n",
    "                      batchify_fn, \n",
    "                      batch_size=128, \n",
    "                      shuffle=True, \n",
    "                      sampler=BatchSampler):\n",
    "\n",
    "    if not isinstance(dataset, MapDataset):\n",
    "        dataset = MapDataset(dataset)\n",
    "        \n",
    "    dataset.map(trans_fn)\n",
    "    batch_sampler = sampler(dataset, \n",
    "                            shuffle=shuffle, \n",
    "                            batch_size=batch_size)\n",
    "    \n",
    "    dataloder = DataLoader(dataset, \n",
    "                           batch_sampler=batch_sampler, \n",
    "                           collate_fn=batchify_fn)\n",
    "    \n",
    "    return dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:31:28.635015Z",
     "iopub.status.busy": "2022-03-27T17:31:28.634676Z",
     "iopub.status.idle": "2022-03-27T17:31:43.106021Z",
     "shell.execute_reply": "2022-03-27T17:31:43.105414Z",
     "shell.execute_reply.started": "2022-03-27T17:31:28.634985Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocab (char): 6255\n"
     ]
    }
   ],
   "source": [
    "text = [t[0] for t in train_set]\n",
    "V = TextVectorizer(list)\n",
    "V.build_vocab(text)\n",
    "print(\"Number of vocab (char):\", len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:37:41.323822Z",
     "iopub.status.busy": "2022-03-27T17:37:41.323126Z",
     "iopub.status.idle": "2022-03-27T17:37:41.527174Z",
     "shell.execute_reply": "2022-03-27T17:37:41.526394Z",
     "shell.execute_reply.started": "2022-03-27T17:37:41.323784Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "include_seq_len = False; batch_size = 1024\n",
    "trans_fn = get_trans_fn(V, include_seq_len=include_seq_len)\n",
    "batchify_fn = get_batchify_fn(include_seq_len=include_seq_len)\n",
    "train_loader = create_dataloader(train_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "dev_loader = create_dataloader(dev_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "test_loader = create_dataloader(test_set, trans_fn, batchify_fn, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:31:43.527094Z",
     "iopub.status.busy": "2022-03-27T17:31:43.526581Z",
     "iopub.status.idle": "2022-03-27T17:31:43.534857Z",
     "shell.execute_reply": "2022-03-27T17:31:43.534351Z",
     "shell.execute_reply.started": "2022-03-27T17:31:43.527064Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle \n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "\n",
    "class BoW(nn.Layer):\n",
    "\n",
    "    def __init__(self, \n",
    "                vocab_size, \n",
    "                output_dim,\n",
    "                embedding_dim=100,\n",
    "                padding_idx=0,  \n",
    "                hidden_dim=50, \n",
    "                activation=nn.ReLU()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        \n",
    "        self.dense = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.activation = activation\n",
    "        self.dense_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def encoder(self, embd):\n",
    "        return embd.sum(axis=1)\n",
    "\n",
    "    def forward(self, text_ids): \n",
    "        text_embd = self.embedding(text_ids)\n",
    "        encoded = self.encoder(text_embd)\n",
    "        hidden_out = self.activation(self.dense(encoded))\n",
    "        out_logits = self.dense_out(hidden_out)\n",
    "        return out_logits\n",
    "\n",
    "\n",
    "def get_model(model):\n",
    "    model = paddle.Model(model)\n",
    "    optimizer = paddle.optimizer.Adam(\n",
    "    parameters=model.parameters(), learning_rate=5e-4)\n",
    "    criterion = paddle.nn.CrossEntropyLoss()\n",
    "    metric = paddle.metric.Accuracy()\n",
    "    model.prepare(optimizer, criterion, metric)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:32:24.121821Z",
     "iopub.status.busy": "2022-03-27T17:32:24.120859Z",
     "iopub.status.idle": "2022-03-27T17:32:28.762152Z",
     "shell.execute_reply": "2022-03-27T17:32:28.761426Z",
     "shell.execute_reply.started": "2022-03-27T17:32:24.121781Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0328 01:32:24.124156  2844 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0328 01:32:24.129127  2844 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "model = BoW(len(V), 3)\n",
    "model = get_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:32:30.954705Z",
     "iopub.status.busy": "2022-03-27T17:32:30.954156Z",
     "iopub.status.idle": "2022-03-27T17:36:49.231891Z",
     "shell.execute_reply": "2022-03-27T17:36:49.231261Z",
     "shell.execute_reply.started": "2022-03-27T17:32:30.954663Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/10\n",
      "step 1000/2144 - loss: 0.1866 - acc: 0.9194 - 16ms/step\n",
      "step 2000/2144 - loss: 0.1780 - acc: 0.9272 - 15ms/step\n",
      "step 2144/2144 - loss: 0.1647 - acc: 0.9278 - 15ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.1745 - acc: 0.9368 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 2/10\n",
      "step 1000/2144 - loss: 0.1725 - acc: 0.9382 - 18ms/step\n",
      "step 2000/2144 - loss: 0.1527 - acc: 0.9395 - 16ms/step\n",
      "step 2144/2144 - loss: 0.1221 - acc: 0.9397 - 16ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.1163 - acc: 0.9428 - 13ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 3/10\n",
      "step 1000/2144 - loss: 0.1226 - acc: 0.9455 - 15ms/step\n",
      "step 2000/2144 - loss: 0.1301 - acc: 0.9467 - 15ms/step\n",
      "step 2144/2144 - loss: 0.0871 - acc: 0.9468 - 15ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.0917 - acc: 0.9489 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 4/10\n",
      "step 1000/2144 - loss: 0.1122 - acc: 0.9512 - 15ms/step\n",
      "step 2000/2144 - loss: 0.1041 - acc: 0.9515 - 15ms/step\n",
      "step 2144/2144 - loss: 0.1298 - acc: 0.9515 - 15ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.1069 - acc: 0.9521 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 5/10\n",
      "step 1000/2144 - loss: 0.1079 - acc: 0.9543 - 15ms/step\n",
      "step 2000/2144 - loss: 0.1259 - acc: 0.9543 - 17ms/step\n",
      "step 2144/2144 - loss: 0.1052 - acc: 0.9544 - 17ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.1944 - acc: 0.9538 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 6/10\n",
      "step 1000/2144 - loss: 0.1097 - acc: 0.9561 - 16ms/step\n",
      "step 2000/2144 - loss: 0.1054 - acc: 0.9562 - 15ms/step\n",
      "step 2144/2144 - loss: 0.1249 - acc: 0.9563 - 15ms/step\n",
      "Eval begin...\n",
      "step 715/715 - loss: 0.1387 - acc: 0.9552 - 14ms/step\n",
      "Eval samples: 731622\n",
      "Epoch 6: Early stopping.\n"
     ]
    }
   ],
   "source": [
    "from paddle.callbacks import EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(patience=3)\n",
    "\n",
    "model.fit(train_loader, dev_loader, epochs=10, verbose=2, log_freq=1000, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T17:37:47.310780Z",
     "iopub.status.busy": "2022-03-27T17:37:47.309775Z",
     "iopub.status.idle": "2022-03-27T17:37:56.530937Z",
     "shell.execute_reply": "2022-03-27T17:37:56.530293Z",
     "shell.execute_reply.started": "2022-03-27T17:37:47.310731Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step  10/715 - loss: 0.1166 - acc: 0.9554 - 18ms/step\n",
      "step  20/715 - loss: 0.1172 - acc: 0.9541 - 15ms/step\n",
      "step  30/715 - loss: 0.1070 - acc: 0.9538 - 14ms/step\n",
      "step  40/715 - loss: 0.0984 - acc: 0.9543 - 14ms/step\n",
      "step  50/715 - loss: 0.1167 - acc: 0.9550 - 14ms/step\n",
      "step  60/715 - loss: 0.0982 - acc: 0.9549 - 14ms/step\n",
      "step  70/715 - loss: 0.1026 - acc: 0.9552 - 14ms/step\n",
      "step  80/715 - loss: 0.1290 - acc: 0.9545 - 13ms/step\n",
      "step  90/715 - loss: 0.0945 - acc: 0.9547 - 13ms/step\n",
      "step 100/715 - loss: 0.1171 - acc: 0.9547 - 13ms/step\n",
      "step 110/715 - loss: 0.1294 - acc: 0.9548 - 13ms/step\n",
      "step 120/715 - loss: 0.1201 - acc: 0.9545 - 13ms/step\n",
      "step 130/715 - loss: 0.1315 - acc: 0.9544 - 13ms/step\n",
      "step 140/715 - loss: 0.1012 - acc: 0.9546 - 13ms/step\n",
      "step 150/715 - loss: 0.0970 - acc: 0.9548 - 13ms/step\n",
      "step 160/715 - loss: 0.0815 - acc: 0.9548 - 13ms/step\n",
      "step 170/715 - loss: 0.0991 - acc: 0.9549 - 13ms/step\n",
      "step 180/715 - loss: 0.1301 - acc: 0.9547 - 13ms/step\n",
      "step 190/715 - loss: 0.1084 - acc: 0.9547 - 13ms/step\n",
      "step 200/715 - loss: 0.1356 - acc: 0.9548 - 13ms/step\n",
      "step 210/715 - loss: 0.1372 - acc: 0.9547 - 13ms/step\n",
      "step 220/715 - loss: 0.1274 - acc: 0.9547 - 13ms/step\n",
      "step 230/715 - loss: 0.1027 - acc: 0.9546 - 13ms/step\n",
      "step 240/715 - loss: 0.1012 - acc: 0.9548 - 13ms/step\n",
      "step 250/715 - loss: 0.1177 - acc: 0.9549 - 13ms/step\n",
      "step 260/715 - loss: 0.1031 - acc: 0.9548 - 13ms/step\n",
      "step 270/715 - loss: 0.1221 - acc: 0.9548 - 13ms/step\n",
      "step 280/715 - loss: 0.1325 - acc: 0.9548 - 13ms/step\n",
      "step 290/715 - loss: 0.1227 - acc: 0.9548 - 13ms/step\n",
      "step 300/715 - loss: 0.1336 - acc: 0.9548 - 13ms/step\n",
      "step 310/715 - loss: 0.1111 - acc: 0.9547 - 13ms/step\n",
      "step 320/715 - loss: 0.1278 - acc: 0.9547 - 13ms/step\n",
      "step 330/715 - loss: 0.0851 - acc: 0.9549 - 13ms/step\n",
      "step 340/715 - loss: 0.1334 - acc: 0.9549 - 13ms/step\n",
      "step 350/715 - loss: 0.1187 - acc: 0.9549 - 13ms/step\n",
      "step 360/715 - loss: 0.1158 - acc: 0.9549 - 13ms/step\n",
      "step 370/715 - loss: 0.1052 - acc: 0.9549 - 13ms/step\n",
      "step 380/715 - loss: 0.1161 - acc: 0.9550 - 13ms/step\n",
      "step 390/715 - loss: 0.1139 - acc: 0.9549 - 13ms/step\n",
      "step 400/715 - loss: 0.1083 - acc: 0.9550 - 13ms/step\n",
      "step 410/715 - loss: 0.1125 - acc: 0.9550 - 13ms/step\n",
      "step 420/715 - loss: 0.1034 - acc: 0.9549 - 13ms/step\n",
      "step 430/715 - loss: 0.1096 - acc: 0.9549 - 13ms/step\n",
      "step 440/715 - loss: 0.1159 - acc: 0.9550 - 13ms/step\n",
      "step 450/715 - loss: 0.1184 - acc: 0.9550 - 13ms/step\n",
      "step 460/715 - loss: 0.0893 - acc: 0.9550 - 13ms/step\n",
      "step 470/715 - loss: 0.1033 - acc: 0.9551 - 13ms/step\n",
      "step 480/715 - loss: 0.0904 - acc: 0.9550 - 13ms/step\n",
      "step 490/715 - loss: 0.0998 - acc: 0.9551 - 13ms/step\n",
      "step 500/715 - loss: 0.1020 - acc: 0.9550 - 13ms/step\n",
      "step 510/715 - loss: 0.1070 - acc: 0.9550 - 13ms/step\n",
      "step 520/715 - loss: 0.1168 - acc: 0.9550 - 13ms/step\n",
      "step 530/715 - loss: 0.1142 - acc: 0.9550 - 13ms/step\n",
      "step 540/715 - loss: 0.1008 - acc: 0.9551 - 13ms/step\n",
      "step 550/715 - loss: 0.1000 - acc: 0.9551 - 13ms/step\n",
      "step 560/715 - loss: 0.0940 - acc: 0.9551 - 13ms/step\n",
      "step 570/715 - loss: 0.1258 - acc: 0.9551 - 13ms/step\n",
      "step 580/715 - loss: 0.1050 - acc: 0.9550 - 13ms/step\n",
      "step 590/715 - loss: 0.1107 - acc: 0.9551 - 13ms/step\n",
      "step 600/715 - loss: 0.1047 - acc: 0.9550 - 13ms/step\n",
      "step 610/715 - loss: 0.1087 - acc: 0.9551 - 13ms/step\n",
      "step 620/715 - loss: 0.1051 - acc: 0.9551 - 13ms/step\n",
      "step 630/715 - loss: 0.1044 - acc: 0.9551 - 13ms/step\n",
      "step 640/715 - loss: 0.1110 - acc: 0.9550 - 13ms/step\n",
      "step 650/715 - loss: 0.1214 - acc: 0.9551 - 13ms/step\n",
      "step 660/715 - loss: 0.1335 - acc: 0.9551 - 13ms/step\n",
      "step 670/715 - loss: 0.1104 - acc: 0.9550 - 13ms/step\n",
      "step 680/715 - loss: 0.1265 - acc: 0.9550 - 13ms/step\n",
      "step 690/715 - loss: 0.1136 - acc: 0.9550 - 13ms/step\n",
      "step 700/715 - loss: 0.1179 - acc: 0.9550 - 13ms/step\n",
      "step 710/715 - loss: 0.1157 - acc: 0.9550 - 13ms/step\n",
      "step 715/715 - loss: 0.0912 - acc: 0.9550 - 13ms/step\n",
      "Eval samples: 731622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.091151156], 'acc': 0.9550177550702412}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
